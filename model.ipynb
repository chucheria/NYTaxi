{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "The client is launching a new ride sharing program in New York similar to Uber or Lyft. At the end of each trip they want their app to suggest a tip amount to the rider. The company has not acquired any of their own data yet, so they have tasked you with producing a model based off of the taxi data. This model should predict the likely tip amount for a trip based on the other trip attributes. You can assume that the ride sharing company can provide data that has the same attributes as the taxi data for each trip.\n",
    "\n",
    "In building the model consider the following requirements:\n",
    "\n",
    "- The model should be built from the taxi dataset. You can supplement the taxi data with external datasets, but this is not a requirement.\n",
    "- Document your choice of model / algorithm, discussing why you chose it over alternatives.\n",
    "    - Document how you assess your models performance.\n",
    "    - Discuss any limitations or caveats of the model which might be an issue in implementing it.\n",
    "    - Discuss how you might improve your model going forward.\n",
    "    - Discuss how you might turn this model in to an API the company can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_new-vars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'PUdate', 'PUhour', 'DOdate', 'DOhour',\n",
       "       'trip_duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['RatecodeID', 'trip_distance',\n",
    "       'PULocationID', 'DOLocationID', 'fare_amount', 'extra', 'tolls_amount',\n",
    "       'total_amount', 'PUhour']]\n",
    "y = df.tip_amount\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>PUhour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>1</td>\n",
       "      <td>0.74</td>\n",
       "      <td>230</td>\n",
       "      <td>162</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>1</td>\n",
       "      <td>0.40</td>\n",
       "      <td>68</td>\n",
       "      <td>249</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9234</th>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>68</td>\n",
       "      <td>164</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.55</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6862</th>\n",
       "      <td>1</td>\n",
       "      <td>1.60</td>\n",
       "      <td>162</td>\n",
       "      <td>246</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RatecodeID  trip_distance  PULocationID  DOLocationID  fare_amount  \\\n",
       "8371           1           0.74           230           162          5.5   \n",
       "5027           1           0.40            68           249          4.0   \n",
       "9234           1           0.99            68           164          5.5   \n",
       "3944           1           0.90            74            75          5.5   \n",
       "6862           1           1.60           162           246         14.5   \n",
       "\n",
       "      extra  tolls_amount  total_amount  PUhour  \n",
       "8371    0.0           0.0          6.30      14  \n",
       "5027    0.0           0.0          4.80      14  \n",
       "9234    0.0           0.0          7.30      14  \n",
       "3944    0.0           0.0          7.55      14  \n",
       "6862    0.0           0.0         15.30      14  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestRegressor(random_state=42)\n",
    "param_grid = { \n",
    "    \"n_estimators\" : [10,20,30],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion' :['mse', 'mae']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [10, 20, 30], 'max_features': ['sqrt', 'log2'], 'criterion': ['mse', 'mae']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=3)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mae', 'max_features': 'sqrt', 'n_estimators': 30}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = RandomForestRegressor(bootstrap=True,\n",
    "                                    criterion='mae',\n",
    "                                    max_features='sqrt',\n",
    "                                    min_samples_split=2,\n",
    "                                    n_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,\n",
       "           max_features='sqrt', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_params.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rfc_params.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random Forest on CV data:  1.4028680665151514\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE for Random Forest on CV data: \",mean_squared_error(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose a Random Forest model because it performs significally well as a regresor, there's no need for feature normalization, it reduces overfitting, and trains relatively fast. Combined with the grid search for parameters selection, they provide a good regression model without knowing the data thoroughly.\n",
    "\n",
    "Having said that, xgboost or neural networks usually perform better but they are slower to train and the model engineering needs more work. Also, Random Forest are hard to interpret and usually perform worst than a xgboost on a bigger dataset.\n",
    "\n",
    "Next steps to improve this model:\n",
    "    \n",
    "    - Do feature engineeering.\n",
    "    - Move from sklearn to TensorFlow or Coffee to customize the model and increase accuracy.\n",
    "    - Change the model in case the performance is worse as said before.\n",
    "    \n",
    "To make a API we would have to use a stream to calculate predictions based on the model used for input. Basically, each time data is upload the model would predict and return those predictions. The model should be trained once a day/week/etc to maintain accuracy depending on how often new data is entered in the system.\n",
    "This workflow has a component of data cleaning and wrangling for the model to be able to interpret it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
